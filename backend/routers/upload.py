import io
import json
import traceback
import tempfile
import os
from fastapi import APIRouter, UploadFile, File, Form
from fastapi.responses import JSONResponse
import PyPDF2
from io import BytesIO
import chardet
from docx import Document
from langchain_community.document_loaders import PyPDFLoader

from services.subscribtion_service import (
    check_and_reset_subscription, 
    deduct_pages
)
from services.text_processing import deep_clean_farsi_text, looks_garbled
from db_config import supabase

router = APIRouter()

def count_pdf_pages(pdf_bytes: bytes) -> int:
    try:
        pdf_reader = PyPDF2.PdfReader(BytesIO(pdf_bytes))
        return len(pdf_reader.pages)
    except Exception as e:
        print(f"Error counting PDF pages: {e}")
        return 0

@router.post("/upload_json")
async def upload_json(
        user_id: str = Form(...),
        category: str = Form(...),
        file: UploadFile = File(...)
):
    print("UPLOAD_JSON RECEIVED CATEGORY:", repr(category))

    # 1. Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø´ØªØ±Ø§Ú© Ú©Ø§Ø±Ø¨Ø±
    subscription = await check_and_reset_subscription(user_id)
    if not subscription:
        return JSONResponse(
            status_code=402,  # Payment Required
            content={"error": "Ù„Ø·ÙØ§ Ø§Ø¨ØªØ¯Ø§ Ø§Ø´ØªØ±Ø§Ú© Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯"}
        )

    # 2. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª
    content = await file.read()
    filename = file.filename.lower() if file.filename else ""

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª
    pages_count = 1  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØºÛŒØ± PDF
    if filename.endswith(".pdf"):
        pages_count = count_pdf_pages(content)
        if pages_count == 0:
            return JSONResponse(
                status_code=400,
                content={"error": "ÙØ§ÛŒÙ„ PDF Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª ÛŒØ§ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ÛŒØ³Øª"}
            )

    # 3. Ø§Ø¹Ù…Ø§Ù„ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø´ØªØ±Ø§Ú©
    if subscription.plan_type == "free":
        # Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†ØŒ ÙÙ‚Ø· 3 ØµÙØ­Ù‡ Ø§ÙˆÙ„
        max_pages = 3
        if pages_count > max_pages:
            # ÙÙ‚Ø· 3 ØµÙØ­Ù‡ Ø§ÙˆÙ„ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ù†
            pages_to_process = max_pages
            pages_to_deduct = 0  # Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù† ØµÙØ­Ø§Øª Ú©Ø³Ø± Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
            warning = f"ØªÙˆØ¬Ù‡: Ø¯Ø± Ù¾Ù„Ù† Ø±Ø§ÛŒÚ¯Ø§Ù† ÙÙ‚Ø· {max_pages} ØµÙØ­Ù‡ Ø§ÙˆÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø§Ø² {pages_count} ØµÙØ­Ù‡)"
        else:
            pages_to_process = pages_count
            pages_to_deduct = pages_count
            warning = None
    else:
        # Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù¾Ø±Ø¯Ø§Ø®Øªâ€ŒÚ©Ù†Ù†Ø¯Ù‡
        if pages_count > subscription.pages_remaining:
            return JSONResponse(
                status_code=402,
                content={
                    "error": f"ØµÙØ­Ø§Øª Ú©Ø§ÙÛŒ Ø¯Ø± Ø§Ø´ØªØ±Ø§Ú© Ø´Ù…Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯",
                    "details": {
                        "required_pages": pages_count,
                        "available_pages": subscription.pages_remaining,
                        "plan": subscription.plan_type
                    }
                }
            )
        pages_to_process = pages_count
        pages_to_deduct = pages_count
        warning = None

    # 4. Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ (Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØµÙØ­Ø§Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†)
    json_data = {}
    try:
        if filename.endswith(".json"):
            json_data = json.loads(content.decode("utf-8", errors="ignore"))

        elif filename.endswith(".pdf"):
            print(f"ğŸ“„ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ PDF: {file.filename}")
            print(f"ğŸ“¦ ØµÙØ­Ø§Øª Ú©Ù„: {pages_count}")
            print(f"ğŸ“„ ØµÙØ­Ø§Øª Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´: {pages_to_process}")

            with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp_pdf:
                tmp_pdf.write(content)
                pdf_path = tmp_pdf.name

            context = ""
            context_blocks = []
            use_ocr = False

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ PDF Ø¨Ø§ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØµÙØ­Ø§Øª
            try:
                reader = PyPDFLoader(pdf_path)
                pages = reader.load()

                # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØµÙØ­Ø§Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†
                if subscription.plan_type == "free" and len(pages) > pages_to_process:
                    pages = pages[:pages_to_process]

                print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ ØµÙØ­Ø§Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {len(pages)}")

                for page_num, page in enumerate(pages, 1):
                    page_text = page.page_content
                    cleaned_text = deep_clean_farsi_text(page_text)
                    if cleaned_text:
                        context += cleaned_text + "\n\n"
                        context_blocks.append({
                            "page": page_num,
                            "text": cleaned_text,
                            "char_count": len(cleaned_text)
                        })

                if len(context.strip()) < 50 or looks_garbled(context):
                    use_ocr = True

            except Exception as e:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± PyPDFLoader: {str(e)}")
                use_ocr = True

            # Ù…Ø±Ø­Ù„Ù‡ 2: Ø§Ú¯Ø± Ù†ÛŒØ§Ø² Ø¨Ù‡ OCR Ø¨ÙˆØ¯ØŒ Ø§Ø² PyMuPDF Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            if use_ocr:
                print("ğŸ” Ù†ÛŒØ§Ø² Ø¨Ù‡ OCR ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯...")
                try:
                    # ØªÙ„Ø§Ø´ Ø¨Ø§ PyMuPDF Ø§Ú¯Ø± Ù†ØµØ¨ Ø¨Ø§Ø´Ø¯
                    try:
                        import fitz  # PyMuPDF
                        print("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² PyMuPDF Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†...")
                        doc = fitz.open(pdf_path)
                        
                        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† ØµÙØ­Ø§Øª Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†
                        if subscription.plan_type == "free" and pages_count > 3:
                            page_range = range(min(3, len(doc)))
                        else:
                            page_range = range(len(doc))
                            
                        for page_num in page_range:
                            page = doc.load_page(page_num)
                            text = page.get_text()
                            if text:
                                cleaned_text = deep_clean_farsi_text(text)
                                context += cleaned_text + "\n\n"
                                context_blocks.append({
                                    "page": page_num + 1,
                                    "text": cleaned_text,
                                    "char_count": len(cleaned_text),
                                    "method": "pymupdf"
                                })
                        doc.close()
                    except ImportError:
                        print("PyMuPDF Ù†ØµØ¨ Ù†ÛŒØ³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡...")
                except Exception as e:
                    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ OCR: {str(e)}")

            # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
            try:
                os.unlink(pdf_path)
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª: {str(e)}")

            json_data = {
                "filename": file.filename,
                "category": category.strip().lower(),
                "extraction_method": "ocr" if use_ocr else "text",
                "total_characters": len(context),
                "total_blocks": len(context_blocks),
                "pages_total": pages_count,
                "pages_processed": pages_to_process,
                "full_text": context,
                "blocks": context_blocks,
                "metadata": {
                    "file_size_bytes": len(content)
                }
            }

        elif filename.endswith(".txt"):
            detected = chardet.detect(content)
            encoding = detected.get("encoding") or "utf-8"
            raw_text = content.decode(encoding, errors="ignore")
            json_data = {"text": deep_clean_farsi_text(raw_text)}

        elif filename.endswith(".docx"):
            doc = Document(io.BytesIO(content))
            full_text = "\n".join([para.text for para in doc.paragraphs])
            json_data = {"text": deep_clean_farsi_text(full_text)}

        else:
            return JSONResponse(
                status_code=400,
                content={"error": "ÙØ±Ù…Øª ÙØ§ÛŒÙ„ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯. ÙÙ‚Ø· JSON, PDF, TXT, DOCX."}
            )

        # 5. Ú©Ø³Ø± ØµÙØ­Ø§Øª Ø§Ø² Ø§Ø´ØªØ±Ø§Ú© (Ø¨Ù‡ Ø¬Ø² Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø±Ø§ÛŒÚ¯Ø§Ù†)
        if subscription.plan_type != "free" and pages_to_deduct > 0:
            success, result = await deduct_pages(user_id, pages_to_deduct)
            if not success:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ú©Ø³Ø± ØµÙØ­Ø§Øª: {result}")

        # 6. Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± Supabase
        related_data = []
        existing = supabase.table("ai_assist").select("*").eq("user_id", user_id).execute()
        if existing.data:
            supabase.table("ai_assist").update({
                "category": category,
                "data": json_data,
                "related_sources": related_data
            }).eq("user_id", user_id).execute()
        else:
            supabase.table("ai_assist").insert({
                "user_id": user_id,
                "category": category,
                "data": json_data,
                "related_sources": related_data
            }).execute()

        response = {
            "message": f"File '{file.filename}' processed successfully âœ…",
            "category": category,
            "file_type": filename.split('.')[-1],
            "subscription_info": {
                "plan": subscription.plan_type,
                "pages_used": pages_to_deduct,
                "pages_remaining": subscription.pages_remaining - pages_to_deduct if subscription.plan_type != "free" else "unlimited",
                "pages_processed": pages_to_process,
                "pages_total": pages_count
            },
            "extraction_summary": {
                "method": json_data.get("extraction_method", "unknown"),
                "total_characters": json_data.get("total_characters", 0),
                "total_blocks": json_data.get("total_blocks", 0)
            },
            "json_data_preview": json.dumps(json_data, ensure_ascii=False)[:500],
        }

        if warning:
            response["warning"] = warning

        return response

    except Exception as e:
        print(f"ERROR in upload_json: {str(e)}")
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"error": f"Processing failed: {str(e)}"})