import io
import tempfile
import os
import traceback
import fitz  # PyMuPDF
import pdfplumber
from services.text_processing import deep_clean_farsi_text
import arabic_reshaper
from bidi.algorithm import get_display
import re

def extract_with_pymupdf(pdf_path: str, max_pages: int = None) -> dict:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ PyMuPDF (Ø¨Ù‡ØªØ±ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ)"""
    context = ""
    context_blocks = []
    
    try:
        doc = fitz.open(pdf_path)
        total_pages = len(doc)
        
        if max_pages and total_pages > max_pages:
            page_range = range(min(max_pages, total_pages))
        else:
            page_range = range(total_pages)
        
        for page_num in page_range:
            page = doc.load_page(page_num)
            
            # Ø±ÙˆØ´ 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø³Ø§Ø¯Ù‡
            text = page.get_text()
            
            # Ø±ÙˆØ´ 2: Ø§Ú¯Ø± Ù…ØªÙ† Ú©Ø§ÙÛŒ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            if not text or len(text.strip()) < 50:
                text_dict = page.get_text("dict")
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± dict
                blocks_text = []
                for block in text_dict.get("blocks", []):
                    if block.get("type") == 0:  # Ù†ÙˆØ¹ text
                        for line in block.get("lines", []):
                            for span in line.get("spans", []):
                                font = span.get("font", "").lower()
                                text_content = span.get("text", "")
                                
                                # Ø¨Ø±Ø±Ø³ÛŒ ÙÙˆÙ†Øª ÙØ§Ø±Ø³ÛŒ
                                if any(font_keyword in font for font_keyword in ['arial', 'tahoma', 'nazanin', 'lotus', 'iran', 'persian']):
                                    # reshape Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
                                    try:
                                        reshaped_text = arabic_reshaper.reshape(text_content)
                                        bidi_text = get_display(reshaped_text)
                                        blocks_text.append(bidi_text)
                                    except:
                                        blocks_text.append(text_content)
                                else:
                                    blocks_text.append(text_content)
                
                text = " ".join(blocks_text)
            
            if text:
                # Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ§Ø±Ø³ÛŒ
                text = fix_farsi_text_issues(text)
                cleaned_text = deep_clean_farsi_text(text)
                
                context += cleaned_text + "\n\n"
                context_blocks.append({
                    "page": page_num + 1,
                    "text": cleaned_text,
                    "char_count": len(cleaned_text),
                    "method": "pymupdf_advanced"
                })
        
        doc.close()
        return {
            "success": True,
            "text": context,
            "blocks": context_blocks,
            "method": "pymupdf"
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± PyMuPDF: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

def extract_with_pdfplumber(pdf_path: str, max_pages: int = None) -> dict:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ pdfplumber (Ø¨Ø±Ø§ÛŒ PDFÙ‡Ø§ÛŒ Ø¨Ø§ Ú©ÛŒÙÛŒØª)"""
    context = ""
    context_blocks = []
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            total_pages = len(pdf.pages)
            
            if max_pages and total_pages > max_pages:
                pages_to_process = min(max_pages, total_pages)
            else:
                pages_to_process = total_pages
            
            for page_num in range(pages_to_process):
                page = pdf.pages[page_num]
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†
                text = page.extract_text()
                
                # Ø§Ú¯Ø± Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯ØŒ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯Ø§ÙˆÙ„ Ù‡Ù… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                if not text or len(text.strip()) < 50:
                    text = page.extract_text(x_tolerance=1, y_tolerance=1)
                
                if text:
                    text = fix_farsi_text_issues(text)
                    cleaned_text = deep_clean_farsi_text(text)
                    
                    context += cleaned_text + "\n\n"
                    context_blocks.append({
                        "page": page_num + 1,
                        "text": cleaned_text,
                        "char_count": len(cleaned_text),
                        "method": "pdfplumber"
                    })
        
        return {
            "success": True,
            "text": context,
            "blocks": context_blocks,
            "method": "pdfplumber"
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± pdfplumber: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

def extract_with_pypdfloader(pdf_path: str, max_pages: int = None) -> dict:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ PyPDFLoader (Ø±ÙˆØ´ Ù‚Ø¯ÛŒÙ…ÛŒ)"""
    try:
        from langchain_community.document_loaders import PyPDFLoader
        
        context = ""
        context_blocks = []
        
        reader = PyPDFLoader(pdf_path)
        pages = reader.load()
        
        if max_pages and len(pages) > max_pages:
            pages = pages[:max_pages]
        
        for page_num, page in enumerate(pages, 1):
            page_text = page.page_content
            if page_text:
                page_text = fix_farsi_text_issues(page_text)
                cleaned_text = deep_clean_farsi_text(page_text)
                
                context += cleaned_text + "\n\n"
                context_blocks.append({
                    "page": page_num,
                    "text": cleaned_text,
                    "char_count": len(cleaned_text),
                    "method": "pypdfloader"
                })
        
        return {
            "success": True,
            "text": context,
            "blocks": context_blocks,
            "method": "pypdfloader"
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± PyPDFLoader: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }

def fix_farsi_text_issues(text: str) -> str:
    """Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬ Ø¯Ø± Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡"""
    if not text:
        return ""
    
    # 1. Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø¹ÛŒÙˆØ¨
    replacements = {
        'Ùƒ': 'Ú©',
        'ÙŠ': 'ÛŒ',
        'Ø©': 'Ù‡',
        'Ø¤': 'Ùˆ',
        'Ø¥': 'Ø§',
        'Ø£': 'Ø§',
        'Ø¢': 'Ø¢',
        'Ù ': 'Û°',
        'Ù¡': 'Û±',
        'Ù¢': 'Û²',
        'Ù£': 'Û³',
        'Ù¤': 'Û´',
        'Ù¥': 'Ûµ',
        'Ù¦': 'Û¶',
        'Ù§': 'Û·',
        'Ù¨': 'Û¸',
        'Ù©': 'Û¹',
        'Ù‚Ù‚ÛŒ': 'Ù‚Ø±Ø§Ø±Ø¯Ø§Ø¯',
        'ØµÛŒ': 'Ø³Ø±Ù…Ø§ÛŒÙ‡',
        'Ù‚ÛŒÛŒ': 'Ø´Ø±Ú©Øª',
        'Ù‡Ø±Ù…ÛŒ': 'Ù‡Ø±Ù…ÛŒ',
        'Ø® ØµÛŒ': 'Ø®ØµÙˆØµÛŒ',
        'Ù‡ÙˆÙ…': 'Ù‡ÙˆÙ…',
        'Ù†Ú¯Ø±': 'Ù†Ú¯Ø§Ø±',
        'Ù¾ÛŒ': 'Ù¾Ø°ÛŒØ±',
        'Ù‚ÛŒØ¨ÙˆØ³': 'Ù‚ÛŒØ¨ÙˆØ³',
        'Ø¯Ø§ÙˆØ¯': 'Ø¯Ø§ÙˆØ¯',
        'Ø¯Ø§ Ø±ÙˆØ¯ÛŒ': 'Ø¯Ø§ÙˆØ±Ø¯ÛŒ',
    }
    
    for wrong, correct in replacements.items():
        text = text.replace(wrong, correct)
    
    # 2. Ø§ØµÙ„Ø§Ø­ ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§
    text = re.sub(r'\s+', ' ', text)
    
    # 3. Ø§ØµÙ„Ø§Ø­ Ø­Ø±ÙˆÙ Ú†Ø³Ø¨ÛŒØ¯Ù‡
    farsi_chars = 'Ø§Ø¨Ù¾ØªØ«Ø¬Ú†Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚Ú©Ú¯Ù„Ù…Ù†ÙˆÙ‡ÛŒ'
    text = re.sub(f'([{farsi_chars}])([{farsi_chars}])', r'\1 \2', text)
    
    # 4. Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„
    text = ''.join(char for char in text if ord(char) >= 32 or char in '\n\r\t')
    
    return text

async def process_pdf_advanced(content: bytes, max_pages: int = None) -> dict:
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ PDF Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø±ÙˆØ´"""
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp_pdf:
        tmp_pdf.write(content)
        pdf_path = tmp_pdf.name
    
    result = None
    methods = [
        ("pymupdf", extract_with_pymupdf),
        ("pdfplumber", extract_with_pdfplumber),
        ("pypdfloader", extract_with_pypdfloader),
    ]
    
    for method_name, extractor in methods:
        print(f"ğŸ” Ø¢Ø²Ù…Ø§ÛŒØ´ Ø±ÙˆØ´ {method_name}...")
        result = extractor(pdf_path, max_pages)
        
        if result["success"]:
            text_length = len(result["text"].strip())
            print(f"âœ… Ø±ÙˆØ´ {method_name} Ù…ÙˆÙÙ‚: {text_length} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡
            if text_length > 100:
                break
            else:
                print(f"âš ï¸ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· {method_name} Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª")
        else:
            print(f"âŒ Ø±ÙˆØ´ {method_name} Ù†Ø§Ù…ÙˆÙÙ‚")
    
    # Ø­Ø°Ù ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚Øª
    try:
        os.unlink(pdf_path)
    except:
        pass
    
    if result and result["success"]:
        return {
            "extraction_method": result["method"],
            "total_characters": len(result["text"]),
            "total_blocks": len(result["blocks"]),
            "full_text": result["text"],
            "blocks": result["blocks"],
            "quality": "good" if len(result["text"].strip()) > 100 else "poor"
        }
    else:
        raise Exception("Ù‡ÛŒÚ† ÛŒÚ© Ø§Ø² Ø±ÙˆØ´â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯Ù†Ø¯")